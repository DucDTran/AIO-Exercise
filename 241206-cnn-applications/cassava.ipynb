{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    'train': \"content/cassavaleafdata/train\",\n",
    "    'valid': \"content/cassavaleafdata/validation\", \n",
    "    'test': \"content/cassavaleafdata/test\"\n",
    "}\n",
    "\n",
    "def loader(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "img_size = 150\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=str(data_paths['train']),\n",
    "    loader=loader,\n",
    "    transform=train_transforms\n",
    ")\n",
    "valid_data = datasets.ImageFolder(\n",
    "    root=str(data_paths['valid']),\n",
    "    transform=train_transforms\n",
    ")\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=str(data_paths['test']),\n",
    "    transform=train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "valid_dataloader = data.DataLoader(\n",
    "    dataset=valid_data,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 150, 150])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_dataloader:\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# LeNet CNN architecture for classification\n",
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        # Initialize parent class\n",
    "        super().__init__()\n",
    "        # First conv layer: 1 input channel (grayscale), 6 output channels, 5x5 kernel with same padding\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=6, kernel_size=5, padding='same'\n",
    "        )\n",
    "        # First pooling layer: 2x2 average pooling\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        # Second conv layer: 6 input channels, 16 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5\n",
    "        )\n",
    "        # Second pooling layer: 2x2 average pooling\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        # Flatten layer to convert 2D feature maps to 1D vector\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "        self.fc_1 = nn.Linear(16*35*35, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs shape: (batch_size, 1, 150, 150)\n",
    "        \n",
    "        # Pass through first conv layer\n",
    "        # outputs shape: (batch_size, 6, 150, 150) - same padding preserves dimensions\n",
    "        outputs = self.conv1(inputs)\n",
    "        \n",
    "        # Apply first average pooling\n",
    "        # outputs shape: (batch_size, 6, 75, 75) - halved spatial dimensions\n",
    "        outputs = self.avgpool1(outputs)\n",
    "        \n",
    "        # Apply ReLU activation - shape remains (batch_size, 6, 75, 75)\n",
    "        outputs = F.relu(outputs)\n",
    "        \n",
    "        # Pass through second conv layer\n",
    "        # outputs shape: (batch_size, 16, 71, 71) - no padding reduces spatial dims by 4\n",
    "        outputs = self.conv2(outputs)\n",
    "        \n",
    "        # Apply second average pooling\n",
    "        # outputs shape: (batch_size, 16, 35, 35) - halved spatial dimensions\n",
    "        outputs = self.avgpool2(outputs)\n",
    "        \n",
    "        # Apply ReLU activation - shape remains (batch_size, 16, 35, 35)\n",
    "        outputs = F.relu(outputs)\n",
    "        \n",
    "        # Flatten 2D feature maps to 1D\n",
    "        # outputs shape: (batch_size, 16*35*35)\n",
    "        outputs = self.flatten(outputs)\n",
    "        # Pass through first FC layer\n",
    "        # outputs shape: (batch_size, 120)\n",
    "        outputs = self.fc_1(outputs)\n",
    "        # Pass through second FC layer\n",
    "        # outputs shape: (batch_size, 84)\n",
    "        outputs = self.fc_2(outputs)\n",
    "        # Pass through output FC layer\n",
    "        # outputs shape: (batch_size, num_classes)\n",
    "        outputs = self.fc_3(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, device, epoch=0, log_interval=50):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create DataLoader if not already a DataLoader\n",
    "    if not isinstance(train_dataloader, torch.utils.data.DataLoader):\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataloader,\n",
    "            batch_size=32,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        # Move batch to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "        \n",
    "        # Print progress\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n",
    "                \"| accuracy {:8.3f}\".format(\n",
    "                    epoch, idx, len(train_dataloader), total_acc / total_count\n",
    "                )\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, valid_dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "\n",
    "    # Create DataLoader if not already a DataLoader\n",
    "    if not isinstance(valid_dataloader, torch.utils.data.DataLoader):\n",
    "        valid_dataloader = torch.utils.data.DataLoader(\n",
    "            valid_dataloader,\n",
    "            batch_size=32,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            # Move batch to device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Calculate accuracy\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  177 batches | accuracy    0.463\n",
      "| epoch   1 |   100/  177 batches | accuracy    0.481\n",
      "| epoch   1 |   150/  177 batches | accuracy    0.489\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   1 | Time: 227.49s | Train Accuracy    0.501 | Train Loss    1.314 | Valid Accuracy    0.508 | Valid Loss    1.268 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |    50/  177 batches | accuracy    0.538\n",
      "| epoch   2 |   100/  177 batches | accuracy    0.539\n",
      "| epoch   2 |   150/  177 batches | accuracy    0.541\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   2 | Time: 229.49s | Train Accuracy    0.566 | Train Loss    1.202 | Valid Accuracy    0.546 | Valid Loss    1.233 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |    50/  177 batches | accuracy    0.563\n",
      "| epoch   3 |   100/  177 batches | accuracy    0.580\n",
      "| epoch   3 |   150/  177 batches | accuracy    0.576\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   3 | Time: 228.86s | Train Accuracy    0.568 | Train Loss    1.136 | Valid Accuracy    0.580 | Valid Loss    1.170 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |    50/  177 batches | accuracy    0.578\n",
      "| epoch   4 |   100/  177 batches | accuracy    0.584\n",
      "| epoch   4 |   150/  177 batches | accuracy    0.596\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   4 | Time: 229.23s | Train Accuracy    0.592 | Train Loss    1.094 | Valid Accuracy    0.581 | Valid Loss    1.126 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |    50/  177 batches | accuracy    0.601\n",
      "| epoch   5 |   100/  177 batches | accuracy    0.611\n",
      "| epoch   5 |   150/  177 batches | accuracy    0.587\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   5 | Time: 231.72s | Train Accuracy    0.583 | Train Loss    1.072 | Valid Accuracy    0.562 | Valid Loss    1.183 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |    50/  177 batches | accuracy    0.618\n",
      "| epoch   6 |   100/  177 batches | accuracy    0.593\n",
      "| epoch   6 |   150/  177 batches | accuracy    0.623\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   6 | Time: 242.83s | Train Accuracy    0.604 | Train Loss    1.031 | Valid Accuracy    0.581 | Valid Loss    1.142 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |    50/  177 batches | accuracy    0.604\n",
      "| epoch   7 |   100/  177 batches | accuracy    0.639\n",
      "| epoch   7 |   150/  177 batches | accuracy    0.631\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   7 | Time: 228.46s | Train Accuracy    0.648 | Train Loss    0.985 | Valid Accuracy    0.562 | Valid Loss    1.151 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |    50/  177 batches | accuracy    0.649\n",
      "| epoch   8 |   100/  177 batches | accuracy    0.634\n",
      "| epoch   8 |   150/  177 batches | accuracy    0.640\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   8 | Time: 230.09s | Train Accuracy    0.610 | Train Loss    0.955 | Valid Accuracy    0.562 | Valid Loss    1.163 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |    50/  177 batches | accuracy    0.661\n",
      "| epoch   9 |   100/  177 batches | accuracy    0.636\n",
      "| epoch   9 |   150/  177 batches | accuracy    0.661\n",
      "-----------------------------------------------------------\n",
      "| End of epoch   9 | Time: 235.93s | Train Accuracy    0.682 | Train Loss    0.914 | Valid Accuracy    0.576 | Valid Loss    1.167 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |    50/  177 batches | accuracy    0.676\n",
      "| epoch  10 |   100/  177 batches | accuracy    0.672\n",
      "| epoch  10 |   150/  177 batches | accuracy    0.691\n",
      "-----------------------------------------------------------\n",
      "| End of epoch  10 | Time: 234.21s | Train Accuracy    0.704 | Train Loss    0.850 | Valid Accuracy    0.577 | Valid Loss    1.266 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_data.classes)\n",
    "\n",
    "lenet_model = LeNetClassifier(num_classes=num_classes)\n",
    "lenet_model.to(device=device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(lenet_model.parameters(), learning_rate)\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "eval_accs, eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_acc, train_loss = train(\n",
    "        model=lenet_model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_dataloader=train_data,\n",
    "        device=device,\n",
    "        epoch=epoch\n",
    "    )\n",
    "\n",
    "    eval_acc, eval_loss = evaluate(\n",
    "        model=lenet_model,\n",
    "        criterion=criterion,\n",
    "        valid_dataloader=valid_data\n",
    "    )\n",
    "    eval_losses.append(eval_loss)\n",
    "\n",
    "    if eval_loss < best_loss_eval:\n",
    "        torch.save(lenet_model.state_dict(), save_model + '/lenet_model.pt')\n",
    "\n",
    "    print(\"-\" * 59)\n",
    "    print(\n",
    "        \"| End of epoch {:3d} | Time: {:5.2f}s | Train Accuracy {:8.3f} | Train Loss {:8.3f} \"\n",
    "        \n",
    "        \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "            epoch, time.time() - epoch_start_time, train_acc, train_loss, eval_acc, eval_loss\n",
    "        )\n",
    "    )\n",
    "    print(\"-\" * 59)\n",
    "\n",
    "    lenet_model.load_state_dict(torch.load(save_model + \"/lenet_model.pt\"))\n",
    "    lenet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5824933687002652, 1.3226159699261189)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_acc, test_loss = evaluate(lenet_model, criterion, test_dataloader)\n",
    "test_acc, test_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
